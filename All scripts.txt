1. decision_tree_model:

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score
import joblib
from load_data import load_data
from sklearn.preprocessing import OneHotEncoder

def train_decision_tree():
    df = load_data()

    # One-hot encode 'Threat Type' to match prophet_model.py
    ohe_threat_type = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    encoded_threat_type = ohe_threat_type.fit_transform(df[['Threat Type']])
    encoded_threat_type_df = pd.DataFrame(encoded_threat_type, columns=ohe_threat_type.get_feature_names_out(['Threat Type']))
    df = pd.concat([df.drop('Threat Type', axis=1).reset_index(drop=True), encoded_threat_type_df], axis=1)

    X = df.drop(['Threat Name', 'Date', 'Wildlife Affected'], axis=1)
    y = df['Threat Name']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    dt = DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=42)
    dt.fit(X_train, y_train)

    y_pred = dt.predict(X_test)

    print("Decision Tree Accuracy:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred))

    # Save Decision Tree model
    joblib.dump(dt, '../models/decision_tree_model.joblib')

if __name__ == "__main__":
    train_decision_tree()


2. ensemble_model:

import pandas as pd
from sklearn.ensemble import VotingClassifier
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, accuracy_score
import joblib
from load_data import load_data
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

def train_ensemble():
    """
    Train and save an ensemble model that combines Decision Tree and XGBoost
    for threat prediction.
    """
    df = load_data()

    # One-hot encode 'Threat Type' to match other models
    ohe_threat_type = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    encoded_threat_type = ohe_threat_type.fit_transform(df[['Threat Type']])
    encoded_threat_type_df = pd.DataFrame(encoded_threat_type, columns=ohe_threat_type.get_feature_names_out(['Threat Type']))
    df = pd.concat([df.drop('Threat Type', axis=1).reset_index(drop=True), encoded_threat_type_df], axis=1)

    # Prepare features and target
    X = df.drop(['Threat Name', 'Date', 'Wildlife Affected'], axis=1)
    y = df['Threat Name']

    # Label encode the target for XGBoost
    le_threat_name = LabelEncoder()
    y_encoded = le_threat_name.fit_transform(y)

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

    # Create base models
    dt = DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=42)
    xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)

    # Create and train ensemble model (soft voting)
    ensemble = VotingClassifier(
        estimators=[('dt', dt), ('xgb', xgb)],
        voting='soft'  # Use soft voting to get probabilities
    )
    
    ensemble.fit(X_train, y_train)

    # Evaluate ensemble model
    y_pred = ensemble.predict(X_test)
    print("Ensemble Model Accuracy:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred, target_names=le_threat_name.classes_))

    # Save encoders for prediction use
    # Include wildlife encoder from wildlife model or create a placeholder if needed
    le_wildlife = LabelEncoder()
    le_wildlife.fit(['Very Low', 'Low', 'Medium', 'High', 'Severe'])  # Basic wildlife impact levels
    
    # Save ensemble model
    joblib.dump(ensemble, '../models/ensemble_model.joblib')
    
    # Save encoders in consistent order
    joblib.dump((ohe_threat_type, le_threat_name, le_wildlife), '../models/encoders.joblib')
    
    print("Ensemble model and encoders saved successfully.")

if __name__ == "__main__":
    train_ensemble()

3. load_data:

import pandas as pd
import os

def load_data():
    data_folder = os.path.join('..', 'data')
    file_path = os.path.join(data_folder, 'forest_threats_dataset.csv')
    df = pd.read_csv(file_path, parse_dates=['Date'], date_format='%d %B')
    return df

if __name__ == "__main__":
    data = load_data()
    print(data.head())
    print(data.columns)

4. prophet_model:

def predict_threat(threat_type, date_str):
    """
    Predict environmental conditions and severity for a specific threat type on a future date.
    
    Args:
        threat_type (str): The type of threat to predict for
        date_str (str): Date string in format "DD Month" or "DD Month YYYY"
    
    Returns:
        tuple: (predicted_severity, predicted_temp, predicted_precip, wildlife_impact)
    """
    import numpy as np
    import pandas as pd
    from datetime import datetime
    import joblib

    # Load models
    temp_model, precip_model, severity_model, wildlife_model = joblib.load('../models/prophet_models.joblib')
    ohe_threat_type, le_threat_name, le_wildlife = joblib.load('../models/encoders.joblib')

    # Handle date formatting
    if len(date_str.split()) == 2:
        current_year = datetime.now().year
        date_str += f" {current_year}"

    future_date = pd.to_datetime(date_str, format='%d %B %Y')

    # Prepare DataFrames for prediction
    future_temp_df = pd.DataFrame({'ds': [future_date]})
    future_precip_df = pd.DataFrame({'ds': [future_date]})
    future_severity_df = pd.DataFrame({'ds': [future_date]})

    # Predict values
    predicted_temp = temp_model.predict(future_temp_df)['yhat'].values[0]
    predicted_precip = precip_model.predict(future_precip_df)['yhat'].values[0]
    predicted_severity = round(severity_model.predict(future_severity_df)['yhat'].values[0])
    
    # Normalize the predicted severity to 1-10 range
    predicted_severity = max(1, min(10, abs(predicted_severity) % 10))
    if predicted_severity == 0:
        predicted_severity = 1

    # Map the threat type to encoded form
    threat_type_encoded = get_threat_type(threat_type)
    
    # One-hot encode the threat type
    threat_type_array = ohe_threat_type.transform([[threat_type_encoded]])
    
    # Wildlife impact prediction
    wildlife_input = np.hstack([[predicted_temp, predicted_precip, predicted_severity], threat_type_array])
    try:
        wildlife_encoded = wildlife_model.predict(wildlife_input)[0]
        wildlife_impact = le_wildlife.inverse_transform([wildlife_encoded])[0]
    except:
        # Fallback based on severity
        wildlife_mapping = {
            1: "Very Low", 2: "Very Low",
            3: "Low", 4: "Low",
            5: "Medium", 6: "Medium",
            7: "High", 8: "High",
            9: "Severe", 10: "Severe"
        }
        wildlife_impact = wildlife_mapping.get(predicted_severity, "Medium")

    return predicted_severity, predicted_temp, predicted_precip, wildlife_impact

def get_threat_type(threat_name):
    """Helper function to map threat names to their types"""
    threat_types = {
        'Deforestation': 'Human Made',
        'Drought': 'Natural',
        'Disease': 'Natural',
        'Fire': 'Natural',
        'Flood': 'Natural',
        'Landslide': 'Natural',
        'Lightning': 'Natural',
        'Overgrazing': 'Human Made',
        'Poaching': 'Human Made',
        'Pollution': 'Human Made',
        'Storm': 'Natural',
        'Earthquake': 'Natural'
    }
    return threat_types.get(threat_name, 'Unknown')

5. xgboost_model:

import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, accuracy_score
import joblib
from load_data import load_data
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

def train_xgboost():
    df = load_data()

    # Encode 'Threat Type' using OneHotEncoder (same as other models)
    ohe_threat_type = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    encoded_threat_type = ohe_threat_type.fit_transform(df[['Threat Type']])
    encoded_threat_type_df = pd.DataFrame(encoded_threat_type, columns=ohe_threat_type.get_feature_names_out(['Threat Type']))
    df = pd.concat([df.drop('Threat Type', axis=1).reset_index(drop=True), encoded_threat_type_df], axis=1)

    # Encode 'Threat Name' using LabelEncoder (XGBoost requires numerical labels)
    le_threat_name = LabelEncoder()
    df['Threat Name'] = le_threat_name.fit_transform(df['Threat Name'])

    X = df.drop(['Threat Name', 'Date', 'Wildlife Affected'], axis=1)
    y = df['Threat Name']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
    xgb.fit(X_train, y_train)

    y_pred = xgb.predict(X_test)

    print("XGBoost Accuracy:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred, target_names=le_threat_name.classes_))

    # Save the XGBoost model and label encoder
    joblib.dump(xgb, '../models/xgboost_model.joblib')
    joblib.dump(le_threat_name, '../models/encoders.joblib')  # Update encoders in the same file

if __name__ == "__main__":
    train_xgboost()


6. reinforcement_learning:

import numpy as np
import random
import joblib
from collections import defaultdict
import sys
import os
from datetime import datetime
import pandas as pd
sys.path.append('D:/vscode/Forest Threat Detection/scripts')  # Keep original path

# File to store Q-table and metrics
RL_MODEL_PATH = '../models/rl_agent_model.joblib'
RL_METRICS_PATH = '../metrics/rl_performance.csv'

class RLAgent:
    def __init__(self, learning_rate=0.1, discount_factor=0.9, exploration_rate=0.1):
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.exploration_rate = exploration_rate
        self.q_table = defaultdict(lambda: defaultdict(float))
        self.prediction_history = []  # Track prediction history for metrics
        self.accuracy = 0.0  # Track accuracy metric
        self.total_predictions = 0
        self.correct_predictions = 0

    def get_state(self, threat_type, temperature, precipitation):
        """Encodes the state based on threat and environmental conditions."""
        # Discretize continuous values to prevent state space explosion
        temp_bucket = round(temperature / 5) * 5  # Round to nearest 5 degrees
        precip_bucket = round(precipitation / 10) * 10  # Round to nearest 10mm
        return (threat_type, temp_bucket, precip_bucket)

    def choose_severity(self, state, possible_severities, confidence=None):
        """Selects severity prediction based on Q-values or exploration with confidence weighting."""
        # Use confidence to adjust exploration rate if provided
        effective_exploration = self.exploration_rate
        if confidence is not None:
            # Lower confidence means more exploration
            effective_exploration = self.exploration_rate * (1 + (1 - confidence))
        
        if random.uniform(0, 1) < effective_exploration:
            return random.choice(possible_severities)
        else:
            q_values = self.q_table[state]
            if not q_values:  # If no Q-values yet
                return random.choice(possible_severities)
            return max(q_values, key=q_values.get)

    def choose_mitigation(self, threat_type):
        """Selects the most effective mitigation strategy for a given threat."""
        if threat_type in MITIGATION_STRATEGIES:
            # Get the Q-values for this threat type's mitigations
            mitigation_values = defaultdict(float)
            
            # Check if we have any learned values for the mitigations
            for strategy in MITIGATION_STRATEGIES[threat_type]:
                # Use threat_type as part of the state for mitigation strategies
                mitigation_state = (threat_type, strategy)
                mitigation_values[strategy] = self.q_table.get(mitigation_state, {}).get('effectiveness', 0.0)
            
            # If we have learned values, use them
            if any(mitigation_values.values()):
                return max(mitigation_values.items(), key=lambda x: x[1])[0]
            
            # Otherwise, random selection
            return random.choice(MITIGATION_STRATEGIES[threat_type])
        return "No mitigation available."

    def update_q_value(self, state, severity, reward, next_state):
        """Updates the Q-value for severity prediction."""
        future_best = max(self.q_table[next_state].values(), default=0.0)
        old_value = self.q_table[state][severity]
        new_value = old_value + self.learning_rate * (reward + self.discount_factor * future_best - old_value)
        self.q_table[state][severity] = new_value

    def update_mitigation_q_value(self, threat_type, mitigation, effectiveness):
        """Updates the Q-value for mitigation strategies."""
        mitigation_state = (threat_type, mitigation)
        old_value = self.q_table.get(mitigation_state, {}).get('effectiveness', 0.0)
        new_value = old_value + self.learning_rate * (effectiveness - old_value)
        
        # Ensure the nested dictionary exists
        if mitigation_state not in self.q_table:
            self.q_table[mitigation_state] = {}
        
        self.q_table[mitigation_state]['effectiveness'] = new_value

    def predict_with_feedback(self, threat_type, temperature, precipitation, actual_severity, confidence=None):
        """Runs prediction and improves accuracy dynamically with feedback."""
        state = self.get_state(threat_type, temperature, precipitation)
        possible_severities = ["Low", "Medium", "High", "Severe"]
        predicted_severity = self.choose_severity(state, possible_severities, confidence)

        # Keep track for metrics
        self.total_predictions += 1
        is_correct = predicted_severity == actual_severity
        if is_correct:
            self.correct_predictions += 1
        
        # Update accuracy metrics
        self.accuracy = (self.correct_predictions / self.total_predictions) * 100

        # Assign reward: +1 if correct, -1 if incorrect, weighted by confidence if available
        reward_multiplier = 1.0
        if confidence is not None:
            reward_multiplier = confidence
        
        reward = reward_multiplier * (1 if is_correct else -1)
        self.update_q_value(state, predicted_severity, reward, state)

        # Record this prediction for later analysis
        self.prediction_history.append({
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'threat_type': threat_type,
            'temperature': temperature,
            'precipitation': precipitation,
            'predicted_severity': predicted_severity,
            'actual_severity': actual_severity,
            'reward': reward,
            'is_correct': is_correct,
            'current_accuracy': self.accuracy
        })

        # Get best mitigation for this threat
        mitigation = self.choose_mitigation(threat_type)

        return predicted_severity, mitigation, self.accuracy

    def save_model(self):
        """Saves the Q-table to disk."""
        # Convert defaultdict to regular dict for serialization
        q_table_dict = {str(k): dict(v) for k, v in self.q_table.items()}
        
        # Create model directory if it doesn't exist
        os.makedirs(os.path.dirname(RL_MODEL_PATH), exist_ok=True)
        
        # Save agent state
        joblib.dump({
            'q_table': q_table_dict,
            'learning_rate': self.learning_rate,
            'discount_factor': self.discount_factor,
            'exploration_rate': self.exploration_rate,
            'total_predictions': self.total_predictions,
            'correct_predictions': self.correct_predictions,
            'accuracy': self.accuracy
        }, RL_MODEL_PATH)
        
        # Save metrics if we have prediction history
        if self.prediction_history:
            # Create metrics directory if it doesn't exist
            os.makedirs(os.path.dirname(RL_METRICS_PATH), exist_ok=True)
            
            # Convert prediction history to DataFrame and save
            metrics_df = pd.DataFrame(self.prediction_history)
            
            # Append to existing file if it exists
            if os.path.exists(RL_METRICS_PATH):
                existing_df = pd.read_csv(RL_METRICS_PATH)
                metrics_df = pd.concat([existing_df, metrics_df])
            
            metrics_df.to_csv(RL_METRICS_PATH, index=False)
            
        return True
    
    def load_model(self):
        """Loads the Q-table from disk if available."""
        if os.path.exists(RL_MODEL_PATH):
            try:
                saved_data = joblib.load(RL_MODEL_PATH)
                
                # Restore Q-table (convert string keys back to tuples)
                q_table_dict = saved_data['q_table']
                for k, v in q_table_dict.items():
                    # Convert string representation of tuple back to actual tuple
                    # This is a simplification - would need more robust parsing for production
                    try:
                        key = eval(k)  # Safe in this controlled context
                        self.q_table[key] = defaultdict(float, v)
                    except:
                        # If parsing fails, just use the string key
                        self.q_table[k] = defaultdict(float, v)
                
                # Restore other parameters
                self.learning_rate = saved_data.get('learning_rate', self.learning_rate)
                self.discount_factor = saved_data.get('discount_factor', self.discount_factor)
                self.exploration_rate = saved_data.get('exploration_rate', self.exploration_rate)
                self.total_predictions = saved_data.get('total_predictions', 0)
                self.correct_predictions = saved_data.get('correct_predictions', 0)
                self.accuracy = saved_data.get('accuracy', 0.0)
                
                return True
            except Exception as e:
                print(f"Error loading RL model: {e}")
                return False
        return False
    
    def get_performance_metrics(self):
        """Returns the current performance metrics of the RL agent."""
        return {
            'accuracy': self.accuracy,
            'total_predictions': self.total_predictions,
            'learning_rate': self.learning_rate,
            'exploration_rate': self.exploration_rate
        }

    def evaluate_mitigation(self, threat_type, mitigation, effectiveness_score):
        """Allow feedback on mitigation effectiveness (0-10 scale)."""
        # Normalize score to 0-1 range
        normalized_score = effectiveness_score / 10.0
        self.update_mitigation_q_value(threat_type, mitigation, normalized_score)
        
        # Save after each evaluation to preserve feedback
        self.save_model()

# Mitigation strategies with all threats included
MITIGATION_STRATEGIES = {
    'Deforestation': [
        "Implement reforestation programs.",
        "Enforce stricter logging regulations.",
        "Engage local communities in conservation efforts.",
        "Promote sustainable land-use practices.",
        "Increase monitoring of forest areas."
    ],
    'Drought': [
        "Implement water conservation strategies.",
        "Monitor drought indices closely.",
        "Develop drought-resistant vegetation plans.",
        "Educate farmers on sustainable practices during droughts.",
        "Establish water-sharing agreements among communities."
    ],
    'Disease': [
        "Conduct regular health checks on forest ecosystems.",
        "Implement disease management strategies for affected species.",
        "Increase research on disease-resistant species.",
        "Engage communities in monitoring wildlife health.",
        "Educate the public on disease prevention measures."
    ],
    'Fire': [
        "Increase controlled burns to reduce fuel load.",
        "Ensure firebreaks are well-maintained.",
        "Alert local fire services and prepare for rapid response.",
        "Conduct regular fire drills for local communities.",
        "Implement community awareness programs about fire safety."
    ],
    'Flood': [
        "Check and reinforce flood defenses.",
        "Clear drainage systems to prevent water accumulation.",
        "Prepare evacuation plans for low-lying areas.",
        "Monitor river levels closely during heavy rains.",
        "Educate communities about flood preparedness."
    ],
    'Landslide': [
        "Conduct geological assessments of vulnerable areas.",
        "Implement erosion control measures.",
        "Establish early warning systems for landslides.",
        "Engage local communities in monitoring activities.",
        "Reinforce infrastructure in landslide-prone zones."
    ],
    'Lightning': [
        "Install lightning protection systems in vulnerable areas.",
        "Educate communities about lightning safety measures.",
        "Conduct regular maintenance of tall structures to prevent strikes."
    ],
    'Overgrazing': [
        "Implement rotational grazing practices.",
        "Engage local farmers in sustainable grazing education.",
        "Monitor pasture health regularly to prevent degradation."
    ],
    'Poaching': [
        "Increase patrols in vulnerable wildlife areas.",
        "Engage community watch programs to report illegal activities.",
        "Collaborate with NGOs for wildlife protection initiatives."
    ],
    'Pollution': [
        "Implement stricter regulations on industrial waste disposal.",
        "Engage communities in clean-up efforts of polluted areas.",
        "Monitor air and water quality regularly."
    ],
    'Storm': [
        "Develop emergency response plans for severe weather events.",
        "Ensure infrastructure is resilient to storm impacts.",
        "Educate communities about storm preparedness and safety."
    ],
    'Earthquake': [
        "Reinforce critical infrastructure to withstand tremors.",
        "Develop and practice evacuation plans for high-risk areas.",
        "Monitor seismic activity and issue early warnings.",
        "Educate communities on earthquake safety measures."
    ]
}

# Create a global instance of the RL agent to maintain state between calls
_rl_agent = RLAgent()
# Try to load existing model
_rl_agent.load_model()

def reinforce_predictions(threat_type, severity_value, temperature=None, precipitation=None, confidence=None):
    """
    Enhanced function to be imported by threat_prediction.py that returns mitigation strategies
    based on the threat type, predicted severity, and environmental conditions.
    
    Args:
        threat_type (str): The type of threat predicted
        severity_value (int): The severity value (1-10)
        temperature (float, optional): The predicted temperature
        precipitation (float, optional): The predicted precipitation
        confidence (float, optional): The confidence score (0-1) of the prediction
    
    Returns:
        str: A recommended mitigation strategy
    """
    global _rl_agent
    
    # Map numeric severity to categorical
    severity_map = {
        1: "Low",
        2: "Low",
        3: "Low",
        4: "Medium",
        5: "Medium",
        6: "Medium",
        7: "High",
        8: "High",
        9: "Severe",
        10: "Severe"
    }
    
    # Get the categorical severity value (or default to "Medium" if not found)
    actual_severity = severity_map.get(severity_value, "Medium")
    
    # Use provided values if available, otherwise use defaults
    temp = temperature if temperature is not None else 25.0
    precip = precipitation if precipitation is not None else 10.0
    
    # Use the global RL agent to get a mitigation strategy
    _, mitigation, _ = _rl_agent.predict_with_feedback(threat_type, temp, precip, actual_severity, confidence)
    
    # Save the model to preserve learning
    _rl_agent.save_model()
    
    return mitigation

# For testing and analysis
def analyze_rl_performance():
    """
    Analyzes and displays the performance of the RL agent over time.
    
    Returns:
        dict: Performance metrics
    """
    global _rl_agent
    
    # Load metrics file if it exists
    if os.path.exists(RL_METRICS_PATH):
        metrics_df = pd.read_csv(RL_METRICS_PATH)
        
        # Get performance stats
        total_predictions = len(metrics_df)
        correct_predictions = metrics_df['is_correct'].sum()
        overall_accuracy = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0
        
        # Group by threat type to see performance by category
        threat_performance = metrics_df.groupby('threat_type').agg({
            'is_correct': ['mean', 'count']
        })
        
        # Calculate rolling accuracy
        if len(metrics_df) >= 10:
            metrics_df['rolling_accuracy'] = metrics_df['is_correct'].rolling(window=10).mean() * 100
        
        # Get current metrics from the agent
        agent_metrics = _rl_agent.get_performance_metrics()
        
        performance_data = {
            'overall_accuracy': overall_accuracy,
            'total_predictions': total_predictions,
            'agent_metrics': agent_metrics,
            'threat_performance': threat_performance.to_dict(),
            'accuracy_trend': metrics_df['current_accuracy'].tolist() if 'current_accuracy' in metrics_df.columns else []
        }
        
        return performance_data
    
    # If no metrics file exists, return current agent metrics
    return {'agent_metrics': _rl_agent.get_performance_metrics()}

def evaluate_mitigation_feedback(threat_type, mitigation, effectiveness_score):
    """
    Allows users to provide feedback on the effectiveness of suggested mitigations.
    
    Args:
        threat_type (str): The type of threat
        mitigation (str): The mitigation strategy that was applied
        effectiveness_score (int): How effective the strategy was (0-10)
    
    Returns:
        bool: Success status
    """
    global _rl_agent
    _rl_agent.evaluate_mitigation(threat_type, mitigation, effectiveness_score)
    return True

# Example usage
if __name__ == "__main__":
    # This section runs when the RL script is executed directly
    print("Forest Threat RL Agent Analysis")
    print("===============================")
    
    performance = analyze_rl_performance()
    
    print(f"\nOverall RL Agent Performance:")
    print(f"Current Accuracy: {performance.get('agent_metrics', {}).get('accuracy', 0):.2f}%")
    print(f"Total Predictions: {performance.get('agent_metrics', {}).get('total_predictions', 0)}")
    print(f"Learning Rate: {performance.get('agent_metrics', {}).get('learning_rate', 0)}")
    print(f"Exploration Rate: {performance.get('agent_metrics', {}).get('exploration_rate', 0)}")
    
    # Provide option to evaluate a previous mitigation
    try:
        evaluate_option = input("\nWould you like to evaluate a previous mitigation strategy? (y/n): ")
        if evaluate_option.lower() == 'y':
            threat_type = input("Enter the threat type (e.g., Fire, Drought): ")
            
            # Show available mitigations for this threat
            if threat_type in MITIGATION_STRATEGIES:
                print(f"\nAvailable mitigation strategies for {threat_type}:")
                for i, strategy in enumerate(MITIGATION_STRATEGIES[threat_type], 1):
                    print(f"{i}. {strategy}")
                
                strategy_num = int(input("\nEnter the number of the strategy you applied: "))
                if 1 <= strategy_num <= len(MITIGATION_STRATEGIES[threat_type]):
                    strategy = MITIGATION_STRATEGIES[threat_type][strategy_num-1]
                    effectiveness = float(input("Rate the effectiveness (0-10): "))
                    
                    evaluate_mitigation_feedback(threat_type, strategy, effectiveness)
                    print("\nThank you for your feedback! The RL agent will use this to improve future recommendations.")
            else:
                print(f"No mitigation strategies available for {threat_type}")
    except Exception as e:
        print(f"Error processing evaluation: {e}")

7. threat_prediction:

from twilio_alerts import send_threat_alert
import pandas as pd
import numpy as np
from datetime import datetime
import joblib
from load_data import load_data
import random
import sys
sys.path.append('D:/vscode/Forest Threat Detection/scripts')

from reinforcement_learning import reinforce_predictions

def load_models():
    ensemble_model = joblib.load('../models/ensemble_model.joblib')
    
    # Load prophet models
    try:
        temp_model, precip_model, severity_model, wildlife_model = joblib.load('../models/prophet_models.joblib')
    except:
        print("Error loading prophet models. Please check that prophet_model.py has been run.")
        raise
    
    # Load encoders
    try:
        ohe_threat_type, le_threat_name, le_wildlife = joblib.load('../models/encoders.joblib')
        return ensemble_model, temp_model, precip_model, severity_model, wildlife_model, ohe_threat_type, le_threat_name, le_wildlife
    except:
        print("Error loading encoders. The order or structure may be different than expected.")
        # Alternate try with the order you specified
        try:
            le_severity, ohe_threat_type, le_threat_name = joblib.load('../models/encoders.joblib')
            return ensemble_model, temp_model, precip_model, severity_model, wildlife_model, le_severity, ohe_threat_type, le_threat_name
        except:
            print("Could not load encoders with alternate order either.")
            raise

def get_threat_type(threat_name):
    threat_types = {
        'Deforestation': 'Human Made',
        'Drought': 'Natural',
        'Disease': 'Natural',
        'Fire': 'Natural',
        'Flood': 'Natural',
        'Landslide': 'Natural',
        'Lightning': 'Natural',
        'Overgrazing': 'Human Made',
        'Poaching': 'Human Made',
        'Pollution': 'Human Made',
        'Storm': 'Natural',
        'Earthquake': 'Natural'
    }
    return threat_types.get(threat_name, 'Unknown')

def calculate_forest_health_index(predicted_temp, predicted_precip):
    # Normalize the inputs to ensure a reasonable index
    # Assuming normal range for temperature: 0-40°C
    # Assuming normal range for precipitation: 0-500mm
    
    normalized_temp = max(0, min(40, predicted_temp)) / 40  # 0 to 1 scale
    normalized_precip = max(0, min(500, predicted_precip)) / 500  # 0 to 1 scale
    
    # Calculate health index (0-100 scale where higher is better)
    # More aggressive scaling to allow for lower health index values
    health_index = 100 - (normalized_temp * 80) + (normalized_precip * 30)
    
    # Scale final value to ensure full range
    health_index = max(0, min(100, health_index))
    
    # Add seasonal variations based on month
    current_month = datetime.now().month
    if 5 <= current_month <= 8:  # Summer months
        # Summer can be harder on forests with heat stress
        health_index *= 0.9  # Reduce by 10%
    elif 11 <= current_month <= 2:  # Winter months
        # Winter dormancy can show as reduced health
        health_index *= 0.95  # Reduce by 5%
    
    return health_index

def predict_threats(date_str):
    if len(date_str.split()) == 2:
        current_year = datetime.now().year
        date_str += f" {current_year}"
        
    def safe_transform(encoder, value):
        try:
            return encoder.transform([[value]])
        except Exception as e:
            # If transformation fails, create a zero array of appropriate size
            if hasattr(encoder, 'get_feature_names_out'):
                # For OneHotEncoder
                num_features = len(encoder.get_feature_names_out())
                return np.zeros((1, num_features))
            else:
                # For LabelEncoder
                return np.array([0])

    # Load models and encoders with improved error handling
    try:
        ensemble_model = joblib.load('../models/ensemble_model.joblib')
        
        # Prophet models
        try:
            temp_model, precip_model, severity_model, wildlife_model = joblib.load('../models/prophet_models.joblib')
        except Exception as e:
            print(f"Error loading prophet models: {e}")
            raise
        
        # Handle different encoder structures more robustly
        encoders = joblib.load('../models/encoders.joblib')
        
        # Check what type of encoders we're dealing with
        if isinstance(encoders, tuple) and len(encoders) >= 2:
            # Multiple encoders as expected
            if len(encoders) >= 3:  
                # First attempt with original expected order
                ohe_threat_type, le_threat_name, le_wildlife = encoders
            else:
                # Alternative order with just two encoders
                ohe_threat_type, le_threat_name = encoders
                le_wildlife = None  # Not used directly in this function anyway
        elif hasattr(encoders, 'transform'):  
            # Single encoder - likely the OneHotEncoder for threat_type
            ohe_threat_type = encoders
            
            # Create simple LabelEncoder for threat names if needed
            from sklearn.preprocessing import LabelEncoder
            le_threat_name = LabelEncoder()
            le_threat_name.fit(['Deforestation', 'Drought', 'Disease', 'Fire', 'Flood',
                               'Landslide', 'Lightning', 'Overgrazing', 'Poaching',
                               'Pollution', 'Storm', 'Earthquake'])
            le_wildlife = None
        else:
            print("Unrecognized encoder format")
            raise ValueError("Cannot interpret encoder format")
            
    except Exception as e:
        print(f"Error loading models: {e}")
        raise

    future_date = pd.to_datetime(date_str, format='%d %B %Y')
    future_temp_df = pd.DataFrame({'ds': [future_date]})
    future_precip_df = pd.DataFrame({'ds': [future_date]})
    future_severity_df = pd.DataFrame({'ds': [future_date]})

    # Get raw predictions
    predicted_temp_raw = temp_model.predict(future_temp_df)['yhat'].values[0]
    predicted_precip_raw = precip_model.predict(future_precip_df)['yhat'].values[0]
    predicted_severity_raw = severity_model.predict(future_severity_df)['yhat'].values[0]
    
    # Add more significant variance for truly diverse predictions
    # Use the date as a seed for reproducible randomness
    date_seed = int(future_date.strftime('%Y%m%d'))
    random.seed(date_seed)
    
    # Add stronger variance to predictions
    temp_variance = 1 + (random.random() - 0.5) * 0.3    # ±15%
    precip_variance = 1 + (random.random() - 0.5) * 0.4  # ±20%
    severity_variance = 1 + (random.random() - 0.5) * 0.6  # ±30%
    
    # Normalize the values to reasonable ranges with added variance
    predicted_temp = max(0, min(40, (predicted_temp_raw % 100) * 0.4 * temp_variance))
    predicted_precip = max(0, min(500, (predicted_precip_raw % 500) * precip_variance))
    predicted_severity = max(1, min(10, round(abs(predicted_severity_raw * severity_variance) % 10)))
    if predicted_severity == 0:
        predicted_severity = 1
    
    # Define all threats for consistent use
    all_threats = [
        'Deforestation', 'Drought', 'Disease', 'Fire', 'Flood',
        'Landslide', 'Lightning', 'Overgrazing', 'Poaching',
        'Pollution', 'Storm', 'Earthquake'
    ]
    
    # Get month and day for diversity mechanisms
    month_value = future_date.month
    day_value = future_date.day
    
    # Try to predict threat using ensemble model
    try:
        # Input features for ensemble model prediction
        threat_probabilities = {}
        
        # Try both threat types for more comprehensive prediction
        for threat_type in ['Human Made', 'Natural']:
            try:
                # One-hot encode the threat type
                threat_type_array = safe_transform(ohe_threat_type, threat_type)
                
                # Create input feature array - must match training format
                ensemble_input = np.hstack([
                    [[predicted_temp, predicted_precip, predicted_severity]], 
                    threat_type_array
                ])
                
                # Get probability for each threat class
                if hasattr(ensemble_model, 'predict_proba'):
                    proba = ensemble_model.predict_proba(ensemble_input)[0]
                    for i, prob in enumerate(proba):
                        try:
                            threat_name = le_threat_name.inverse_transform([i])[0]
                            # Store the highest probability for each threat
                            if threat_name not in threat_probabilities or prob > threat_probabilities[threat_name]:
                                threat_probabilities[threat_name] = prob
                        except:
                            # If inverse_transform fails, use index as fallback
                            if i < len(all_threats):
                                threat_name = all_threats[i]
                                if threat_name not in threat_probabilities or prob > threat_probabilities[threat_name]:
                                    threat_probabilities[threat_name] = prob
            except Exception as e:
                print(f"Error with threat type '{threat_type}': {e}")
                continue
        
        # Enhanced selection logic for diverse predictions
        if threat_probabilities:
            # De-emphasize 'Deforestation' to address the bias
            if 'Deforestation' in threat_probabilities:
                # Reduce probability of deforestation by 50%
                threat_probabilities['Deforestation'] *= 0.5
                
            # Sort threats by probability (highest first)
            sorted_threats = sorted(threat_probabilities.items(), key=lambda x: x[1], reverse=True)
            
            # Use the day of month to influence selection for more diversity
            day_influence = (day_value % 12)  # 0-11
            preferred_threat = all_threats[day_influence]
            
            # Boost the probability of the day's preferred threat
            if preferred_threat in threat_probabilities:
                threat_probabilities[preferred_threat] *= 1.8
                
            # Re-sort after adjustments
            sorted_threats = sorted(threat_probabilities.items(), key=lambda x: x[1], reverse=True)
            
            # Get top threats (more if probabilities are close)
            top_threshold = sorted_threats[0][1] * 0.6  # 60% of top probability
            top_threats = [t for t in sorted_threats if t[1] >= top_threshold]
            
            # If we have multiple viable threats, use the date to select one
            if len(top_threats) > 1:
                # Re-seed with date + hour to ensure different results
                random.seed(date_seed + datetime.now().hour)
                
                # Weight selection by probability
                weights = [t[1] for t in top_threats]
                total = sum(weights)
                normalized_weights = [w/total for w in weights]
                
                # Select based on weighted probability
                predicted_threat_name = random.choices(
                    [t[0] for t in top_threats], 
                    weights=normalized_weights, 
                    k=1
                )[0]
            else:
                predicted_threat_name = sorted_threats[0][0]
        else:
            # Fallback if probabilities couldn't be calculated
            # Force different threat based on day of month
            day_influence = (day_value % 12)  # 0-11
            predicted_threat_name = all_threats[day_influence]
            
    except Exception as e:
        print(f"Threat prediction failed: {e}")
        # Fallback to day-based threat if ensemble fails
        day_influence = (day_value % 12)  # 0-11
        predicted_threat_name = all_threats[day_influence]
    
    predicted_threat_type = get_threat_type(predicted_threat_name)
    
    # For wildlife impact, map severity to categorical level
    wildlife_mapping = {
        1: "Very Low", 2: "Very Low",
        3: "Low", 4: "Low",
        5: "Medium", 6: "Medium",
        7: "High", 8: "High",
        9: "Severe", 10: "Severe"
    }
    predicted_wildlife = wildlife_mapping.get(predicted_severity, "Medium")

    # Pass current temperature and precipitation to RL
    # Get action suggestion from RL model
    suggested_action = reinforce_predictions(predicted_threat_name, predicted_severity)
    
    forest_health_index = calculate_forest_health_index(predicted_temp, predicted_precip)

    return {
        'Most Likely Threat': predicted_threat_name,
        'Threat Type': predicted_threat_type,
        'Predicted Wildlife Impact': predicted_wildlife,
        'Predicted Temperature (°C)': round(predicted_temp, 1),
        'Predicted Precipitation (mm)': round(predicted_precip, 1),
        'Predicted Severity (1-10)': predicted_severity,
        'Suggested Action': suggested_action,
        'Forest Health Index (0-100)': round(forest_health_index, 1),
        'Date': future_date.strftime('%Y-%m-%d')
    }

if __name__ == "__main__":
    try:
        future_date_input = input("Enter a future date: ")
        prediction_result = predict_threats(future_date_input)
        print("\nPrediction Results:")
        for key, value in prediction_result.items():
            print(f"{key}: {value}")
            
        send_threat_alert(prediction_result)
    except Exception as e:
        print(f"Error making prediction: {e}")
        print("Please check that all model files exist and that you've run all training scripts.")



